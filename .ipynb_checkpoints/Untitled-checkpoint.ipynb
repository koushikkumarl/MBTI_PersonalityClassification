{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "\n",
    "data = pd.read_csv('TRAIN.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(np.NaN, \" \", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data.iloc[:, 2:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "      <th>Unnamed: 256</th>\n",
       "      <th>Unnamed: 257</th>\n",
       "      <th>Unnamed: 258</th>\n",
       "      <th>Unnamed: 259</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'I like that you are kind</td>\n",
       "      <td>as INFJ I find that I love you all easily</td>\n",
       "      <td>Its so natural to fit next to you and relax</td>\n",
       "      <td>enjoy time and not feel like i have to do thi...</td>\n",
       "      <td>and other social...|||I found that when this ...</td>\n",
       "      <td>and he is laying out hints and you just are g...</td>\n",
       "      <td>me and a enfj i know are in the same place</td>\n",
       "      <td>though I still love him</td>\n",
       "      <td>and he appears to have feelings for me</td>\n",
       "      <td>I wonder if the possibility is there...|||I f...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'^ Oh my you are right. Who really talks like ...</td>\n",
       "      <td>but this love must be fluid? Entp/infj intera...</td>\n",
       "      <td>maybe getting close to two years. To anyone w...</td>\n",
       "      <td>I could cuddle and bond non sexually for the ...</td>\n",
       "      <td>the folks I trust completed are those who not...</td>\n",
       "      <td>trust has become a very interesting thing for...</td>\n",
       "      <td>but nice for sure.|||How long this difficult ...</td>\n",
       "      <td>but I do like someone very much</td>\n",
       "      <td>who is an entp. Around everyone else he is ve...</td>\n",
       "      <td>but around me</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'yep</td>\n",
       "      <td>yep</td>\n",
       "      <td>yep</td>\n",
       "      <td>especially the last one.    yep</td>\n",
       "      <td>agree.|||yep</td>\n",
       "      <td>sounds like me.  funny to have your personali...</td>\n",
       "      <td>and I thought it was a great quote.  I was wo...</td>\n",
       "      <td>how do you use your empathy and intuition in ...</td>\n",
       "      <td>Gosh yes!!!|||Never knew this was an INFP tra...</td>\n",
       "      <td>...|||Yes</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Things that are generalizable to the entire p...</td>\n",
       "      <td>why why why would you do this?! Does it feel ...</td>\n",
       "      <td>so as much as I take care of her she does the...</td>\n",
       "      <td>if you find it tell me! Hugs you! :D|||Why do...</td>\n",
       "      <td>weed makes me go crazy: I get extra paranoid</td>\n",
       "      <td>and go into a weird state of being trapped in...</td>\n",
       "      <td>I don't see it though.|||Oh yes I care about ...</td>\n",
       "      <td>just not like I care for my  favorite people....</td>\n",
       "      <td>same goes for my left hand.  On a side note: ...</td>\n",
       "      <td>maybe I'm a starseed.  I especially love the ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Work: Student.   Hobbies: Studying</td>\n",
       "      <td>gaming</td>\n",
       "      <td>reading</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>anime. Mainly the first 3.   Partnerships: none</td>\n",
       "      <td>and i plan not to have any.   Travel: train</td>\n",
       "      <td>on foot</td>\n",
       "      <td>usually to the local woods or...|||Same. Like...</td>\n",
       "      <td>love isn't concrete</td>\n",
       "      <td>so how can it be made? :S|||.... The meaning ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>'Well</td>\n",
       "      <td>mostly I don't like avocado. But</td>\n",
       "      <td>the primary problem here is the fact that I i...</td>\n",
       "      <td>no excuse for it. :cool:|||Considering I'm do...</td>\n",
       "      <td>I WAS going to say my last google was what do...</td>\n",
       "      <td>that is now untrue as curiosity compelled me ...</td>\n",
       "      <td>and she was drunk.....I've never seen her dri...</td>\n",
       "      <td>103 degree weather.|||BLECH! :bored: (sorry)|...</td>\n",
       "      <td>child good things come in time.|||Sweet baby ...</td>\n",
       "      <td>put on a patient smile. You promised tomorrow...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>'http://prikachi.com/images/801/8386801y.jpg h...</td>\n",
       "      <td>rather than trying to validate your point</td>\n",
       "      <td>you are busy explaining your opponent what's ...</td>\n",
       "      <td>and the motivation behind his opinion...|||ht...</td>\n",
       "      <td>I find it amusing :laughing:|||I don't know</td>\n",
       "      <td>I think it would be very difficult</td>\n",
       "      <td>stressful and self-destructing for me to try ...</td>\n",
       "      <td>that seems arrogant but...|||Long post of pic...</td>\n",
       "      <td>in the spoiled text:   http://prikachi.com/im...</td>\n",
       "      <td>but I wanted to share these</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>'Cigarettes are like hamsters. perfectly harmless</td>\n",
       "      <td>until you put one in your mouth and light it ...</td>\n",
       "      <td>i smoked a pack a day for 6 months while trav...</td>\n",
       "      <td>self-conscious to the point of obsession</td>\n",
       "      <td>...|||that we blank out a lot. that we aren't ...</td>\n",
       "      <td>we are always pensive</td>\n",
       "      <td>poised</td>\n",
       "      <td>composed and well adjusted every moment of......</td>\n",
       "      <td>i hope not. this world isnt losing any novelt...</td>\n",
       "      <td>i want some more of it first.|||damn... thats...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>'Bookshelf Porn|||As a non-American</td>\n",
       "      <td>please excuse my foreign terminology.  I was ...</td>\n",
       "      <td>white</td>\n",
       "      <td>or brown</td>\n",
       "      <td>housed in porcelain white quarters</td>\n",
       "      <td>with an equally white...|||I'll try to find c...</td>\n",
       "      <td>thanks!|||511601  511609  511617  511625|||51...</td>\n",
       "      <td>you may like that rendition as well.)   http:...</td>\n",
       "      <td>people</td>\n",
       "      <td>like you.|||Monkey see.  (Monkey learn.)  Mon...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>'I respect your opinion. I don't really know a...</td>\n",
       "      <td>this hurts me emotionally because of a person...</td>\n",
       "      <td>Fe so strong but so rooted in Ni that it come...</td>\n",
       "      <td>this strikes me as less of an INFJ thing and ...</td>\n",
       "      <td>I'd find it...|||Pretty straight forward line...</td>\n",
       "      <td>were you inherently charming? Did you immedia...</td>\n",
       "      <td>very intelligent</td>\n",
       "      <td>and willful. My mother...|||If you still requ...</td>\n",
       "      <td>feel free to hit me up in the PMs.|||I'm not ...</td>\n",
       "      <td>I love to play pretend</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts  \\\n",
       "0                             'I like that you are kind   \n",
       "1     '^ Oh my you are right. Who really talks like ...   \n",
       "2                                                  'yep   \n",
       "3     'Things that are generalizable to the entire p...   \n",
       "4                   'Work: Student.   Hobbies: Studying   \n",
       "...                                                 ...   \n",
       "6935                                              'Well   \n",
       "6936  'http://prikachi.com/images/801/8386801y.jpg h...   \n",
       "6937  'Cigarettes are like hamsters. perfectly harmless   \n",
       "6938                'Bookshelf Porn|||As a non-American   \n",
       "6939  'I respect your opinion. I don't really know a...   \n",
       "\n",
       "                                             Unnamed: 3  \\\n",
       "0             as INFJ I find that I love you all easily   \n",
       "1      but this love must be fluid? Entp/infj intera...   \n",
       "2                                                   yep   \n",
       "3      why why why would you do this?! Does it feel ...   \n",
       "4                                                gaming   \n",
       "...                                                 ...   \n",
       "6935                   mostly I don't like avocado. But   \n",
       "6936         rather than trying to validate your point    \n",
       "6937   until you put one in your mouth and light it ...   \n",
       "6938   please excuse my foreign terminology.  I was ...   \n",
       "6939   this hurts me emotionally because of a person...   \n",
       "\n",
       "                                             Unnamed: 4  \\\n",
       "0           Its so natural to fit next to you and relax   \n",
       "1      maybe getting close to two years. To anyone w...   \n",
       "2                                                   yep   \n",
       "3      so as much as I take care of her she does the...   \n",
       "4                                               reading   \n",
       "...                                                 ...   \n",
       "6935   the primary problem here is the fact that I i...   \n",
       "6936   you are busy explaining your opponent what's ...   \n",
       "6937   i smoked a pack a day for 6 months while trav...   \n",
       "6938                                              white   \n",
       "6939   Fe so strong but so rooted in Ni that it come...   \n",
       "\n",
       "                                             Unnamed: 5  \\\n",
       "0      enjoy time and not feel like i have to do thi...   \n",
       "1      I could cuddle and bond non sexually for the ...   \n",
       "2                       especially the last one.    yep   \n",
       "3      if you find it tell me! Hugs you! :D|||Why do...   \n",
       "4                                                  DVDs   \n",
       "...                                                 ...   \n",
       "6935   no excuse for it. :cool:|||Considering I'm do...   \n",
       "6936   and the motivation behind his opinion...|||ht...   \n",
       "6937           self-conscious to the point of obsession   \n",
       "6938                                           or brown   \n",
       "6939   this strikes me as less of an INFJ thing and ...   \n",
       "\n",
       "                                             Unnamed: 6  \\\n",
       "0      and other social...|||I found that when this ...   \n",
       "1      the folks I trust completed are those who not...   \n",
       "2                                          agree.|||yep   \n",
       "3          weed makes me go crazy: I get extra paranoid   \n",
       "4       anime. Mainly the first 3.   Partnerships: none   \n",
       "...                                                 ...   \n",
       "6935   I WAS going to say my last google was what do...   \n",
       "6936       I find it amusing :laughing:|||I don't know    \n",
       "6937  ...|||that we blank out a lot. that we aren't ...   \n",
       "6938                 housed in porcelain white quarters   \n",
       "6939   I'd find it...|||Pretty straight forward line...   \n",
       "\n",
       "                                             Unnamed: 7  \\\n",
       "0      and he is laying out hints and you just are g...   \n",
       "1      trust has become a very interesting thing for...   \n",
       "2      sounds like me.  funny to have your personali...   \n",
       "3      and go into a weird state of being trapped in...   \n",
       "4           and i plan not to have any.   Travel: train   \n",
       "...                                                 ...   \n",
       "6935   that is now untrue as curiosity compelled me ...   \n",
       "6936                I think it would be very difficult    \n",
       "6937                              we are always pensive   \n",
       "6938   with an equally white...|||I'll try to find c...   \n",
       "6939   were you inherently charming? Did you immedia...   \n",
       "\n",
       "                                             Unnamed: 8  \\\n",
       "0            me and a enfj i know are in the same place   \n",
       "1      but nice for sure.|||How long this difficult ...   \n",
       "2      and I thought it was a great quote.  I was wo...   \n",
       "3      I don't see it though.|||Oh yes I care about ...   \n",
       "4                                               on foot   \n",
       "...                                                 ...   \n",
       "6935   and she was drunk.....I've never seen her dri...   \n",
       "6936   stressful and self-destructing for me to try ...   \n",
       "6937                                             poised   \n",
       "6938   thanks!|||511601  511609  511617  511625|||51...   \n",
       "6939                                   very intelligent   \n",
       "\n",
       "                                             Unnamed: 9  \\\n",
       "0                               though I still love him   \n",
       "1                       but I do like someone very much   \n",
       "2      how do you use your empathy and intuition in ...   \n",
       "3      just not like I care for my  favorite people....   \n",
       "4      usually to the local woods or...|||Same. Like...   \n",
       "...                                                 ...   \n",
       "6935   103 degree weather.|||BLECH! :bored: (sorry)|...   \n",
       "6936   that seems arrogant but...|||Long post of pic...   \n",
       "6937   composed and well adjusted every moment of......   \n",
       "6938   you may like that rendition as well.)   http:...   \n",
       "6939   and willful. My mother...|||If you still requ...   \n",
       "\n",
       "                                            Unnamed: 10  \\\n",
       "0                and he appears to have feelings for me   \n",
       "1      who is an entp. Around everyone else he is ve...   \n",
       "2      Gosh yes!!!|||Never knew this was an INFP tra...   \n",
       "3      same goes for my left hand.  On a side note: ...   \n",
       "4                                   love isn't concrete   \n",
       "...                                                 ...   \n",
       "6935   child good things come in time.|||Sweet baby ...   \n",
       "6936   in the spoiled text:   http://prikachi.com/im...   \n",
       "6937   i hope not. this world isnt losing any novelt...   \n",
       "6938                                             people   \n",
       "6939   feel free to hit me up in the PMs.|||I'm not ...   \n",
       "\n",
       "                                            Unnamed: 11  ... Unnamed: 250  \\\n",
       "0      I wonder if the possibility is there...|||I f...  ...                \n",
       "1                                         but around me  ...                \n",
       "2                                             ...|||Yes  ...                \n",
       "3      maybe I'm a starseed.  I especially love the ...  ...                \n",
       "4      so how can it be made? :S|||.... The meaning ...  ...                \n",
       "...                                                 ...  ...          ...   \n",
       "6935   put on a patient smile. You promised tomorrow...  ...                \n",
       "6936                       but I wanted to share these   ...                \n",
       "6937   i want some more of it first.|||damn... thats...  ...                \n",
       "6938   like you.|||Monkey see.  (Monkey learn.)  Mon...  ...                \n",
       "6939                             I love to play pretend  ...                \n",
       "\n",
       "     Unnamed: 251 Unnamed: 252 Unnamed: 253 Unnamed: 254 Unnamed: 255  \\\n",
       "0                                                                       \n",
       "1                                                                       \n",
       "2                                                                       \n",
       "3                                                                       \n",
       "4                                                                       \n",
       "...           ...          ...          ...          ...          ...   \n",
       "6935                                                                    \n",
       "6936                                                                    \n",
       "6937                                                                    \n",
       "6938                                                                    \n",
       "6939                                                                    \n",
       "\n",
       "     Unnamed: 256 Unnamed: 257 Unnamed: 258 Unnamed: 259  \n",
       "0                                                         \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...           ...          ...          ...          ...  \n",
       "6935                                                      \n",
       "6936                                                      \n",
       "6937                                                      \n",
       "6938                                                      \n",
       "6939                                                      \n",
       "\n",
       "[6940 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data_text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6940 entries, 0 to 6939\n",
      "Columns: 258 entries, posts to Unnamed: 259\n",
      "dtypes: object(258)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,100):\n",
    "    data_text['posts'] = data_text['posts'].astype(str).str.cat(data['Unnamed: ' + str(i)].astype(str), sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_posts = pd.DataFrame(data_text['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'I like that you are kind  as INFJ I find that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'^ Oh my you are right. Who really talks like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'yep  yep  yep  especially the last one.    ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Things that are generalizable to the entire p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Work: Student.   Hobbies: Studying  gaming  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>'Well  mostly I don't like avocado. But  the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>'http://prikachi.com/images/801/8386801y.jpg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>'Cigarettes are like hamsters. perfectly harml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>'Bookshelf Porn|||As a non-American  please ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>'I respect your opinion. I don't really know a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts\n",
       "0     'I like that you are kind  as INFJ I find that...\n",
       "1     '^ Oh my you are right. Who really talks like ...\n",
       "2     'yep  yep  yep  especially the last one.    ye...\n",
       "3     'Things that are generalizable to the entire p...\n",
       "4     'Work: Student.   Hobbies: Studying  gaming  r...\n",
       "...                                                 ...\n",
       "6935  'Well  mostly I don't like avocado. But  the p...\n",
       "6936  'http://prikachi.com/images/801/8386801y.jpg h...\n",
       "6937  'Cigarettes are like hamsters. perfectly harml...\n",
       "6938  'Bookshelf Porn|||As a non-American  please ex...\n",
       "6939  'I respect your opinion. I don't really know a...\n",
       "\n",
       "[6940 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = data['type'] + data_posts['posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.concat([data['type'], data_posts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'I like that you are kind  as INFJ I find that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'^ Oh my you are right. Who really talks like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'yep  yep  yep  especially the last one.    ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Things that are generalizable to the entire p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Work: Student.   Hobbies: Studying  gaming  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Well  mostly I don't like avocado. But  the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://prikachi.com/images/801/8386801y.jpg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Cigarettes are like hamsters. perfectly harml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Bookshelf Porn|||As a non-American  please ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'I respect your opinion. I don't really know a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     ENFP  'I like that you are kind  as INFJ I find that...\n",
       "1     INFJ  '^ Oh my you are right. Who really talks like ...\n",
       "2     INFP  'yep  yep  yep  especially the last one.    ye...\n",
       "3     INFJ  'Things that are generalizable to the entire p...\n",
       "4     INTJ  'Work: Student.   Hobbies: Studying  gaming  r...\n",
       "...    ...                                                ...\n",
       "6935  INFJ  'Well  mostly I don't like avocado. But  the p...\n",
       "6936  INFJ  'http://prikachi.com/images/801/8386801y.jpg h...\n",
       "6937  INFJ  'Cigarettes are like hamsters. perfectly harml...\n",
       "6938  INTJ  'Bookshelf Porn|||As a non-American  please ex...\n",
       "6939  INFJ  'I respect your opinion. I don't really know a...\n",
       "\n",
       "[6940 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.preprocessing.text import one_hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed.drop('type', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = df_processed['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['type'] = df_processed['type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
       "0      0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1      0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "2      0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "3      0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "4      0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "6935   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6936   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6937   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6938   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "6939   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "\n",
       "[6940 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc_df = pd.DataFrame(enc.fit_transform(data[['type']]).toarray().astype(int))\n",
    "enc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = enc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "y = pd.get_dummies(df_processed['type']).values\n",
    "print('Shape of label tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
       "0      0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "1      0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "2      0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "3      0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "4      0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "6935   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6936   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6937   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "6938   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "6939   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "\n",
       "[6940 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Koushik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Preprocessing\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    print(i)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['posts'][i])\n",
    "    review = re.sub('\\|\\|\\|', ' ', messages['posts'][i]) \n",
    "    review = re.sub('https?\\S+', '', messages['posts'][i])\n",
    "    review = re.sub('\\s+', ' ', messages['posts'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('CorpusLines.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for item in corpus:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('CorpusLines.txt', 'r', encoding=\"utf-8\") \n",
    "Lines = file1.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr = [one_hot(words, voc_size)for words in Lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1487 14935  2655 ...  3900  2287  7864]\n",
      " [ 6589  5208  6896 ...  8873 11670  8867]\n",
      " [ 2734  3782  4744 ...   409  8912 14381]\n",
      " ...\n",
      " [ 3463  7071  2655 ...  4349  6747 14381]\n",
      " [ 1362  5489  4337 ...  3782 11126 14381]\n",
      " [13212 13770  8485 ...  5856 12778 14381]]\n"
     ]
    }
   ],
   "source": [
    "sent_length = 300\n",
    "embedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1487, 14935,  2655,   423,   391,  4247, 14839,  3782,   120,\n",
       "       13615,  4927, 10096, 13436,  7247,  4409,  8366,  4617, 10037,\n",
       "         602,  4124,  9191,  7287,  8366,  5904,  3968,  1872, 13051,\n",
       "       14996,  1632,  4124, 14393,  4124,  5245, 12264,  6896, 14468,\n",
       "       13850,  9361,  4703,  4545,  3142, 12971, 14935,  4124, 13929,\n",
       "        2501, 11995,  9564,  3782,  8459, 11397, 14314,  4617,  7696,\n",
       "       12615, 10611,  5194,  3412,  7787,  5801,  3700,   594,  7361,\n",
       "        6664,  7361, 13436,  6896, 14839,  6266, 11437,  7290, 14839,\n",
       "        6180,  8042,  9534, 13393,  9879, 14262,  2032, 13152,  6270,\n",
       "        4853,  6679,  9574,  5624,  3190,  8375, 10127,  8894,   521,\n",
       "        6270,  4853,  6679,  9574,  5624,  3190,  8375, 10127,  8894,\n",
       "         521,  6270,  5303,  7012, 14287,  4405, 12728, 11670,  4124,\n",
       "        6421, 14839,  5904, 11017, 11808,  8108,  8669,  5489,   290,\n",
       "        7287,  6230,  4434, 13451,  5622,  5245,  1440, 10877,  5250,\n",
       "       12644,  6978,  1318, 11623, 10716,  6015,  6270,  4498,  7696,\n",
       "       10901,  4124, 11456, 13436,  6597,  3598,  1676,  2501,  2492,\n",
       "        4377,  6653,  8108,  4748,   431,  6287,  5378,  6679,  1968,\n",
       "        6747,   942,   300, 12778, 11070,  2501, 13620,  1527,  4853,\n",
       "       13436,  5610,  1979,  1314,  3587, 13615,   193,  1038,  1867,\n",
       "         688,  5954,  4124,  6601,  4740,  6270,  1499,  3334,  3809,\n",
       "        4124,  5904,   448, 12166,  7204, 11230,   337,  9406, 11070,\n",
       "        6287,  2501,  5809,  6529,    57,  5378, 10383, 14314,  5013,\n",
       "        6270,  3816, 10478,  2501,  3190, 14105,  1968,  5815, 13770,\n",
       "        8531,  1635, 10937,  4364,  6079,  7904, 12606, 10613,  2498,\n",
       "        6270,  3534,  5303,  8691,  7468,  5044,  8239,  8485, 11007,\n",
       "       11670,  6422, 11808, 10983, 14737,  3968, 13436,  5809,  2501,\n",
       "       13126,  1878,  2501, 11367,  3245, 14492,  4364,  6079, 13483,\n",
       "          57,  3534,  3784,  3105, 14244, 14333,  3420,  4377,  6747,\n",
       "       12778,  6310, 12751,  1154,  5771,   535,  8108, 10462,  1342,\n",
       "        7912, 14161, 11644,  3534,  7235,  8345, 10108,  5489,  5094,\n",
       "        5610,  7304,  1342, 11565,  2501, 14033, 10383, 14468, 13298,\n",
       "        1652,  2392, 14745, 14314,  4853,  3399,  1342, 10448,  6294,\n",
       "        2655,  2040, 11995,  7781,  6679,  1632,  3190,  6682, 13123,\n",
       "        3900,  2287,  7864])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          4500000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 1000)              3204000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16016     \n",
      "=================================================================\n",
      "Total params: 7,720,016\n",
      "Trainable params: 7,720,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Bidirectional(LSTM(500)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, (6940, 16))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs), y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "X_final = np.array(embedded_docs)\n",
    "y_final = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6940, 300), (6940, 16))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape, y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "87/87 [==============================] - 22s 250ms/step - loss: 2.3362 - accuracy: 0.1990 - val_loss: 2.2871 - val_accuracy: 0.2068\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 21s 244ms/step - loss: 2.1952 - accuracy: 0.2777 - val_loss: 2.2563 - val_accuracy: 0.2291\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 21s 245ms/step - loss: 1.7768 - accuracy: 0.4751 - val_loss: 2.5218 - val_accuracy: 0.2284\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 21s 245ms/step - loss: 1.0207 - accuracy: 0.7077 - val_loss: 2.8694 - val_accuracy: 0.2378\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 21s 245ms/step - loss: 0.4874 - accuracy: 0.8696 - val_loss: 3.2885 - val_accuracy: 0.2039\n",
      "Epoch 6/20\n",
      "42/87 [=============>................] - ETA: 10s - loss: 0.2252 - accuracy: 0.9438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-7de83aa7034d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\KerasEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasEnv",
   "language": "python",
   "name": "kerasenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
