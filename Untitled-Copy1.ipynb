{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "data = pd.read_csv('TRAIN.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "      <th>Unnamed: 256</th>\n",
       "      <th>Unnamed: 257</th>\n",
       "      <th>Unnamed: 258</th>\n",
       "      <th>Unnamed: 259</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'I like that you are kind</td>\n",
       "      <td>as INFJ I find that I love you all easily</td>\n",
       "      <td>Its so natural to fit next to you and relax</td>\n",
       "      <td>enjoy time and not feel like i have to do thi...</td>\n",
       "      <td>and other social...|||I found that when this ...</td>\n",
       "      <td>and he is laying out hints and you just are g...</td>\n",
       "      <td>me and a enfj i know are in the same place</td>\n",
       "      <td>though I still love him</td>\n",
       "      <td>and he appears to have feelings for me</td>\n",
       "      <td>I wonder if the possibility is there...|||I f...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'^ Oh my you are right. Who really talks like ...</td>\n",
       "      <td>but this love must be fluid? Entp/infj intera...</td>\n",
       "      <td>maybe getting close to two years. To anyone w...</td>\n",
       "      <td>I could cuddle and bond non sexually for the ...</td>\n",
       "      <td>the folks I trust completed are those who not...</td>\n",
       "      <td>trust has become a very interesting thing for...</td>\n",
       "      <td>but nice for sure.|||How long this difficult ...</td>\n",
       "      <td>but I do like someone very much</td>\n",
       "      <td>who is an entp. Around everyone else he is ve...</td>\n",
       "      <td>but around me</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'yep</td>\n",
       "      <td>yep</td>\n",
       "      <td>yep</td>\n",
       "      <td>especially the last one.    yep</td>\n",
       "      <td>agree.|||yep</td>\n",
       "      <td>sounds like me.  funny to have your personali...</td>\n",
       "      <td>and I thought it was a great quote.  I was wo...</td>\n",
       "      <td>how do you use your empathy and intuition in ...</td>\n",
       "      <td>Gosh yes!!!|||Never knew this was an INFP tra...</td>\n",
       "      <td>...|||Yes</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Things that are generalizable to the entire p...</td>\n",
       "      <td>why why why would you do this?! Does it feel ...</td>\n",
       "      <td>so as much as I take care of her she does the...</td>\n",
       "      <td>if you find it tell me! Hugs you! :D|||Why do...</td>\n",
       "      <td>weed makes me go crazy: I get extra paranoid</td>\n",
       "      <td>and go into a weird state of being trapped in...</td>\n",
       "      <td>I don't see it though.|||Oh yes I care about ...</td>\n",
       "      <td>just not like I care for my  favorite people....</td>\n",
       "      <td>same goes for my left hand.  On a side note: ...</td>\n",
       "      <td>maybe I'm a starseed.  I especially love the ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Work: Student.   Hobbies: Studying</td>\n",
       "      <td>gaming</td>\n",
       "      <td>reading</td>\n",
       "      <td>DVDs</td>\n",
       "      <td>anime. Mainly the first 3.   Partnerships: none</td>\n",
       "      <td>and i plan not to have any.   Travel: train</td>\n",
       "      <td>on foot</td>\n",
       "      <td>usually to the local woods or...|||Same. Like...</td>\n",
       "      <td>love isn't concrete</td>\n",
       "      <td>so how can it be made? :S|||.... The meaning ...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  \\\n",
       "0                          'I like that you are kind   \n",
       "1  '^ Oh my you are right. Who really talks like ...   \n",
       "2                                               'yep   \n",
       "3  'Things that are generalizable to the entire p...   \n",
       "4                'Work: Student.   Hobbies: Studying   \n",
       "\n",
       "                                          Unnamed: 3  \\\n",
       "0          as INFJ I find that I love you all easily   \n",
       "1   but this love must be fluid? Entp/infj intera...   \n",
       "2                                                yep   \n",
       "3   why why why would you do this?! Does it feel ...   \n",
       "4                                             gaming   \n",
       "\n",
       "                                          Unnamed: 4  \\\n",
       "0        Its so natural to fit next to you and relax   \n",
       "1   maybe getting close to two years. To anyone w...   \n",
       "2                                                yep   \n",
       "3   so as much as I take care of her she does the...   \n",
       "4                                            reading   \n",
       "\n",
       "                                          Unnamed: 5  \\\n",
       "0   enjoy time and not feel like i have to do thi...   \n",
       "1   I could cuddle and bond non sexually for the ...   \n",
       "2                    especially the last one.    yep   \n",
       "3   if you find it tell me! Hugs you! :D|||Why do...   \n",
       "4                                               DVDs   \n",
       "\n",
       "                                          Unnamed: 6  \\\n",
       "0   and other social...|||I found that when this ...   \n",
       "1   the folks I trust completed are those who not...   \n",
       "2                                       agree.|||yep   \n",
       "3       weed makes me go crazy: I get extra paranoid   \n",
       "4    anime. Mainly the first 3.   Partnerships: none   \n",
       "\n",
       "                                          Unnamed: 7  \\\n",
       "0   and he is laying out hints and you just are g...   \n",
       "1   trust has become a very interesting thing for...   \n",
       "2   sounds like me.  funny to have your personali...   \n",
       "3   and go into a weird state of being trapped in...   \n",
       "4        and i plan not to have any.   Travel: train   \n",
       "\n",
       "                                          Unnamed: 8  \\\n",
       "0         me and a enfj i know are in the same place   \n",
       "1   but nice for sure.|||How long this difficult ...   \n",
       "2   and I thought it was a great quote.  I was wo...   \n",
       "3   I don't see it though.|||Oh yes I care about ...   \n",
       "4                                            on foot   \n",
       "\n",
       "                                          Unnamed: 9  \\\n",
       "0                            though I still love him   \n",
       "1                    but I do like someone very much   \n",
       "2   how do you use your empathy and intuition in ...   \n",
       "3   just not like I care for my  favorite people....   \n",
       "4   usually to the local woods or...|||Same. Like...   \n",
       "\n",
       "                                         Unnamed: 10  \\\n",
       "0             and he appears to have feelings for me   \n",
       "1   who is an entp. Around everyone else he is ve...   \n",
       "2   Gosh yes!!!|||Never knew this was an INFP tra...   \n",
       "3   same goes for my left hand.  On a side note: ...   \n",
       "4                                love isn't concrete   \n",
       "\n",
       "                                         Unnamed: 11  ... Unnamed: 250  \\\n",
       "0   I wonder if the possibility is there...|||I f...  ...                \n",
       "1                                      but around me  ...                \n",
       "2                                          ...|||Yes  ...                \n",
       "3   maybe I'm a starseed.  I especially love the ...  ...                \n",
       "4   so how can it be made? :S|||.... The meaning ...  ...                \n",
       "\n",
       "  Unnamed: 251 Unnamed: 252 Unnamed: 253 Unnamed: 254 Unnamed: 255  \\\n",
       "0                                                                    \n",
       "1                                                                    \n",
       "2                                                                    \n",
       "3                                                                    \n",
       "4                                                                    \n",
       "\n",
       "  Unnamed: 256 Unnamed: 257 Unnamed: 258 Unnamed: 259  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace(np.NaN, \" \", inplace=True)\n",
    "data_posts = data.iloc[:, 2:260].astype(str)\n",
    "data_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,100):\n",
    "    data_posts['posts'] = data_posts['posts'].astype(str).str.cat(data_posts['Unnamed: ' + str(i)].astype(str), sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_posts = pd.DataFrame(data_posts['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'I like that you are kind  as INFJ I find that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'^ Oh my you are right. Who really talks like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'yep  yep  yep  especially the last one.    ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Things that are generalizable to the entire p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Work: Student.   Hobbies: Studying  gaming  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>'Well  mostly I don't like avocado. But  the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>'http://prikachi.com/images/801/8386801y.jpg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>'Cigarettes are like hamsters. perfectly harml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>'Bookshelf Porn|||As a non-American  please ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>'I respect your opinion. I don't really know a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  posts\n",
       "0     'I like that you are kind  as INFJ I find that...\n",
       "1     '^ Oh my you are right. Who really talks like ...\n",
       "2     'yep  yep  yep  especially the last one.    ye...\n",
       "3     'Things that are generalizable to the entire p...\n",
       "4     'Work: Student.   Hobbies: Studying  gaming  r...\n",
       "...                                                 ...\n",
       "6935  'Well  mostly I don't like avocado. But  the p...\n",
       "6936  'http://prikachi.com/images/801/8386801y.jpg h...\n",
       "6937  'Cigarettes are like hamsters. perfectly harml...\n",
       "6938  'Bookshelf Porn|||As a non-American  please ex...\n",
       "6939  'I respect your opinion. I don't really know a...\n",
       "\n",
       "[6940 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.preprocessing.text import one_hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = df_processed['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = data['type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer \n",
    "\n",
    "labels=data_labels.index.tolist()\n",
    "encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
    "labels=encoder.fit_transform(labels)\n",
    "labels=np.array(labels)\n",
    "print(labels[50:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6940"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6940, 260)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "text=pd.read_csv('TRAIN.csv',index_col='type', low_memory=False)\n",
    "text.reset_index(inplace=True)\n",
    "print(text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# One hot encode labels\n",
    "labels=text.index.tolist()\n",
    "encoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
    "labels=encoder.fit_transform(labels)\n",
    "labels=np.array(labels)\n",
    "print(labels[50:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "y = pd.get_dummies(df_processed['type']).values\n",
    "print('Shape of label tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940, 6940)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Preprocessing\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "ps = PorterStemmer()\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    print(i)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['posts'][i])\n",
    "    review = re.sub('\\|\\|\\|', ' ', messages['posts'][i]) \n",
    "    review = re.sub('https?\\S+', '', messages['posts'][i])\n",
    "    review = re.sub('\\s+', ' ', messages['posts'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('CorpusLines.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for item in corpus:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('CorpusLines.txt', 'r', encoding=\"utf-8\") \n",
    "Lines = file1.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr = [one_hot(words, voc_size)for words in Lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length = 200\n",
    "embedded_docs = pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_vector_features, input_length=sent_length))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(500)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedded_docs), y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "X_final = np.array(embedded_docs)\n",
    "y_final = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.shape, y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KerasEnv",
   "language": "python",
   "name": "kerasenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
